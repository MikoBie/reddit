{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wegetarianizm -- Polska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "\n",
    "## stop_words = stopwords.words('polish')\n",
    "## Get the tokens to connect to Reddit Oficial API\n",
    "client_id = os.getenv(\"Reddit_Client_Id\")\n",
    "client_secret = os.getenv('Reddit_Client_Secret')\n",
    "password = os.getenv('Reddit_password')\n",
    "user_agent = os.getenv('Reddit_User_Agent')\n",
    "username = os.getenv('Reddit_Username')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret = client_secret,\n",
    "    password=password,\n",
    "    user_agent=user_agent,\n",
    "    username=username\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator for creating a dictionary\n",
    "def read_tokens():\n",
    "    with open('comments.jl', 'r') as file:\n",
    "        for line in file:\n",
    "            temp = json.loads(line)\n",
    "            yield temp['tokens']\n",
    "\n",
    "## New class for corpus. It streams docs or if the model is provided it returns results of LDA\n",
    "class MyCorpus:\n",
    "    def __init__(self, path = 'comments.jl', model=None, dictionary=None):\n",
    "        self.path = path\n",
    "        self.model = model\n",
    "    def __iter__(self):\n",
    "        with open(self.path, 'r') as file:\n",
    "            for doc in file:\n",
    "                temp = json.loads(doc)\n",
    "                if not self.model:\n",
    "                    yield dictionary.doc2bow(temp['tokens'])\n",
    "                else:\n",
    "                    topics = self.model.get_document_topics(dictionary.doc2bow(temp['tokens']))\n",
    "                    topic, prob = sorted( topics, key = lambda x: x[1], reverse=True)[0]\n",
    "                    temp['topic'] = topic\n",
    "                    temp['prob'] = prob\n",
    "                    top_terms = self.model.get_topic_terms(topic, 100)\n",
    "                    temp['top_tokens'] = { dictionary.id2token[id] : prob for id, prob in top_terms }\n",
    "                    yield temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all submissions from Reddit Polska that contain a word \n",
    "## wegetarianizm\n",
    "subreddit = reddit.subreddit('Polska').search('wegetarianizm')\n",
    "## Create a list of dictionaries with the submissions\n",
    "submissions = [ { 'title' : line.title,\n",
    "                  'id' : line.id,\n",
    "                  'upvote_ratio' : line.upvote_ratio,\n",
    "                  'selftext' : line.selftext,\n",
    "                  'score' : line.score,\n",
    "                  'flair' : line.link_flair_text,\n",
    "                  'num_comments' : line.num_comments,\n",
    "                  'is_self' : line.is_self} \n",
    "               for line in subreddit ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information we can get from a submissions. The following fields are out there but probably we don't need all of them. I put them here just in case.\n",
    "\n",
    "* author -- provides an instance of Redditor.\n",
    "* author_flair_text -- the text content of the author’s flair, or None if not flaired. In simple terms, a flair on reddit is a kind of tag added to either post or username. They are meant to categorize posts or users.\n",
    "* clicked -- whether or not the submission has been clicked by the client.\n",
    "* comments -- provides an instance of CommentForest.\n",
    "* created_utc -- time the submission was created, represented in Unix Time.\n",
    "* distinguished -- whether or not the submission is distinguished.\n",
    "* edited -- Whether or not the submission has been edited.\n",
    "* id -- ID of the submission.\n",
    "* is_original_content -- whether or not the submission has been set as original content.\n",
    "* is_self -- whether or not the submission is a selfpost (text-only).\n",
    "* link_flair_template_id -- the link flair’s ID.\n",
    "* link_flair_text -- The link flair’s text content, or None if not flaired.\n",
    "* locked -- whether or not the submission has been locked.\n",
    "* name -- Fullname of the submission.\n",
    "* num_comments -- the number of comments on the submission.\n",
    "* over_18 -- whether or not the submission has been marked as NSFW.\n",
    "* permalink -- a permalink for the submission.\n",
    "* poll_data -- a PollData object representing the data of this submission, if it is a poll submission.\n",
    "* saved -- whether or not the submission is saved.\n",
    "* score -- the number of upvotes for the submission.\n",
    "* selftext -- the submissions’ selftext - an empty string if a link post.\n",
    "* spoiler -- whether or not the submission has been marked as a spoiler.\n",
    "* stickied -- whether or not the submission is stickied.\n",
    "* subreddit -- provides an instance of Subreddit.\n",
    "* title -- the title of the submission.\n",
    "* upvote_ratio -- the percentage of upvotes from all votes on the submission.\n",
    "* url -- the URL the submission links to, or the permalink if a selfpost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just print out the most important information about each submission.\n",
    "for sub in submissions: print({ 'id' : sub['id'], 'title' : sub['title'], 'num_comments' : sub['num_comments'] })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information on a single comment. The following fields are otu there but probably we don't need all of them. I put them here just in case.jjj\n",
    "\n",
    "* author -- provides an instance of Redditor.\n",
    "* body -- the body of the comment, as Markdown.\n",
    "* body_html -- he body of the comment, as HTML.\n",
    "* created_utc -- time the comment was created, represented in Unix Time.\n",
    "* distinguished -- whether or not the comment is distinguished.\n",
    "* edited -- whether or not the comment has been edited.\n",
    "* id -- the ID of the comment.\n",
    "* is_submitter -- whether or not the comment author is also the author of the submission.\n",
    "* link_id -- the submission ID that the comment belongs to.\n",
    "* parent_id -- he ID of the parent comment (prefixed with t1_). If it is a top-level comment, this returns the submission ID instead (prefixed with t3_).\n",
    "* permalink -- a permalink for the comment. Comment objects from the inbox have a context attribute instead.\n",
    "* replies -- provides an instance of CommentForest.\n",
    "* saved -- whether or not the comment is saved.\n",
    "* score -- the number of upvotes for the comment.\n",
    "* stickied -- whether or not the comment is stickied.\n",
    "* submission -- provides an instance of Submission. The submission that the comment belongs to.\n",
    "* subreddit -- provides an instance of Subreddit. The subreddit that the comment belongs to.\n",
    "* subreddit_id -- the subreddit ID that the comment belongs to.\n",
    "\n",
    "And for the Redditor\n",
    "\n",
    "* comment_karma -- the comment karma for the Redditor.\n",
    "* comments -- provide an instance of SubListing for comment access.\n",
    "* submissions -- provide an instance of SubListing for submission access.\n",
    "* created_utc -- time the account was created, represented in Unix Time.\n",
    "* has_verified_email -- whether or not the Redditor has verified their email.\n",
    "* icon_img -- the url of the Redditors’ avatar.\n",
    "* id -- the ID of the Redditor.\n",
    "* is_employee -- whether or not the Redditor is a Reddit employee.\n",
    "* is_friend -- whether or not the Redditor is friends with the authenticated user.\n",
    "* is_mod -- whether or not the Redditor mods any subreddits.\n",
    "* is_gold -- whether or not the Redditor has active Reddit Premium status.\n",
    "* is_suspended -- whether or not the Redditor is currently suspended.\n",
    "* link_karma -- the link karma for the Redditor.\n",
    "* name -- the Redditor’s username.\n",
    "* subreddit -- if the Redditor has created a user-subreddit, provides a dictionary of additional attributes. See below.\n",
    "* subreddit[\"banner_img\"] -- the URL of the user-subreddit banner.\n",
    "* subreddit[\"name\"]-- the fullname of the user-subreddit.\n",
    "* subreddit[\"over_18\"] -- whether or not the user-subreddit is NSFW.\n",
    "* subreddit[\"public_description\"] -- the public description of the user-subreddit.\n",
    "* subreddit[\"subscribers\"] -- the number of users subscribed to the user-subreddit.\n",
    "* subreddit[\"title\"] -- the title of the user-subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select a submission by id -- this one is about vegetarianism and veganism\n",
    "## on the Reddit Polska.\n",
    "submission = reddit.submission(\"vnapm6\")\n",
    "\n",
    "## Create an empty list to store data about comments.\n",
    "comments = []\n",
    "\n",
    "## Set the option to get all the comments\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "## Iterate over all the comments. Ignore the comments\n",
    "## tree. Write the comments to the JSON line file.\n",
    "with open('comments.jl', 'w') as file:\n",
    "  for comment in submission.comments.list():\n",
    "      temp_dict = {}\n",
    "      temp_dict['body'] = comment.body\n",
    "      temp_dict['score'] = comment.score\n",
    "      try:\n",
    "          temp_dict['author'] = { 'name' : comment.author.name,\n",
    "                                  'karma' : comment.author.comment_karma,\n",
    "                                  'created_utc' : datetime.fromtimestamp(comment.author.created_utc).strftime('%d-%m-%Y %H:%M:%S'),\n",
    "                                  'has_verified_email' : comment.author.has_verified_email,\n",
    "                                  #'is_suspended' : comment.author.is_suspended,\n",
    "                                  'is_gold' : comment.author.is_gold\n",
    "          }\n",
    "      except:\n",
    "          pass\n",
    "      temp_dict['created_utc'] = datetime.fromtimestamp(comment.created_utc).strftime('%d-%m-%Y %H:%M:%S')\n",
    "      temp_dict['edited'] = comment.edited\n",
    "      temp_dict['is_submitter'] = comment.is_submitter\n",
    "      text_nlp = nlp(temp_dict['body'].lower())\n",
    "      temp_dict['tokens'] = [ token.lemma_ for token in text_nlp if len(token) > 1 and token.pos_ not in ['PUNCT', 'ADP', 'CCONJ', 'X' ] ]\n",
    "      \n",
    "      comments.append(temp_dict)\n",
    "      file.write(json.dumps(temp_dict) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary( read_tokens() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 5\n",
    "passes = 100\n",
    "iterations = 400\n",
    "eval_every = None  ## Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=MyCorpus(dictionary=dictionary),\n",
    "    id2word=id2word,\n",
    "    ## chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = MyCorpus(dictionary=dictionary)\n",
    "top_topics = model.top_topics(corpus)\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([ item['top_tokens'] for item in MyCorpus(model=model) if item['topic'] == 1 ][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d55d0eb9076beff1aad1bfd9ab8f276d192cdf8ff5403c32a6f6618edbf4e356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
