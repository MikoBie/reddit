{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHLDxJdRzBi"
   },
   "source": [
    "# Topic Modeling with BERTopic\n",
    "\n",
    "This is based on the Tutorial on BERTopic which you can find [here](https://github.com/MaartenGr/BERTopic). You can find there some tutorials on how to use BERTopic for topic modeling. They go more into detail than I did in this notebook. However, I tried to put the most important things here.\n",
    "\n",
    "\n",
    "## BERTopic\n",
    "In a nutshell, BERTopic is a topic modeling technique that leverages [transformers](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) and a custom class-based TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions. If you want to read the whole story [here](https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6) is the link with more details.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\" width=\"40%\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "130PIKarkY1_"
   },
   "source": [
    "# Enabling the GPU\n",
    "\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-dow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj2MUI9Mkdxu"
   },
   "source": [
    "# **Installing BERTopic**\n",
    "\n",
    "We start by installing BERTopic from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install bertopic\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3VGFZ1USMTu"
   },
   "source": [
    "# Data\n",
    "\n",
    "Let's load our data from `submissions.jl`. In theory, the method we are using does not require any preprocessing, however, I will just remove from the texts emails, and URLs. Otherwise, they will appear in the topics and we don't need it. It is just a simple loop that tokenizes the texts, recognizes URLs and emails, and removes them. Afterward, it appends all the texts into a list called `texts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJij3WP6SEQD"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open(\"comments_opinions_veganisms.jl\", \"r\") as file:\n",
    "    for submission in file:\n",
    "        temp = json.loads(submission)\n",
    "        text = temp[\"body\"]\n",
    "        ## Remove email addresses\n",
    "        text = re.sub(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", \"\", text)\n",
    "        ## Remove URLs\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        temp[\"text\"] = text\n",
    "        texts.append(temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play a bit with removing some texts. I removed the ones that were shorter than 10 words but you can play a bit with that. You can also see whether some texts that are too long should be also removed (for various reasons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove texts shorter than 10 words\n",
    "docs = [line for line in texts if len(line[\"text\"].split()) > 10]\n",
    "\n",
    "## Create a data frame\n",
    "df = pd.DataFrame(docs)\n",
    "\n",
    "## Extract from a data frame a list-like object with texts\n",
    "texts = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visualization of the length of texts. They are pretty short in general. The majority is less than 200 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a list with lengths of texts\n",
    "length = [len(item.split()) for item in texts]\n",
    "\n",
    "## Draw a histogram\n",
    "plt.hist(length, density=False, bins=30)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Length of the submission\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QI6vwelqnTL-"
   },
   "source": [
    "# Training\n",
    "\n",
    "This is where all the magic happens. The chunk below will take the longest and you should more or less execute it only once. What is happening here is converting sentences from our texts into embeddings. In other words, we are converting the sentences into a vector and the dimensions will be other sentences from a pre-trained data set (it was trained on around a billion documents). We can change the pre-trained data set but unless you have a very good reason to do so I would stick to this one. [Here](https://www.sbert.net/docs/pretrained_models.html), are some other options in terms of pre-trained data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = sentence_model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few parameters you can play with here. You can change diversity. It ranges from 0 to 1. In simple terms the higher the value the less tolerant the model is to similar words appearing in different topics. In other words, if you set it to 1, topics should have very unlike words as the most representative for each topic, and also the number of topics might increase.\n",
    "\n",
    "The other parameter you can play with is removing stop words. In theory, this approach is based on sentences, not on words but since the texts are quite short the stop words would really trash the most representative words. I added it but you can remove it to check how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548,
     "referenced_widgets": [
      "798eedddaa704ea0a04fa65b8640b0be",
      "66ca258ee2874e488b8972b64d889f5c",
      "d99e5927b57d44349bfcf94b4334cc99",
      "4cd9e6df6814472393213e07863a4701",
      "abf5f707e3f24d28a84770f9dd8afa03",
      "65bfec9362dd48cfb5f0c8d7f436267c",
      "17e59cebe4964559874b0440d59a76e7",
      "8b0f5d94b52c4255b0f041929f1e94c7",
      "bc908403a55e40dca7eb1e320f0134a3",
      "c876c21c2a1043019aeb8040854073b5",
      "17186baf78084adfb48017be113fa63b",
      "8d0244ef96874eb393e3e3ae3310c790",
      "91419be460da41feb947b0c4059a39c3",
      "ef512703df704e08a286a4035e988d4a",
      "c96e38029588444f9edc91668fc36772",
      "c3f45facbaa34eedadab4fea73b883f1",
      "3dc85531b250469980fd796023802770",
      "eabbaf8b64b942ca9caf5d1080c3dec9",
      "c26a2e6bda7840108ce5d3c022b49610",
      "57012ab5600c47c58be5f1a39097eded",
      "6e60e1b8b1004a0d82a81dc08c38e6ce",
      "0c934f6173724e339e169eeec353b40c",
      "c294ab5101b84046a4a5bc5e214b454b",
      "3cfe0d0b22e64682a58a27c0ff1bf75d",
      "c1b010ba842f42e9ae70470cc544678c",
      "dbaae122ac0f4f9e81a05939f6604160",
      "8783968199da4d498940def3de1be412",
      "17f6d103d3114b6a80a96d19ff091b9b",
      "a14bf20f11d44f1d913b76fcf3745a5a",
      "7a47e30771f74d51902f39e0b0e2b0f8",
      "aad52bfe857d47ac90b0640fc0704248",
      "705bbcdbacac4bf38dc272dc348a117f",
      "22ab8cd99fdb496184de1df9b66e07dc",
      "34d3d2bbfc314317894bd919733bde90",
      "11e00b5847e14537bcd47fad849808aa",
      "c3dfeb03063b40f09614551fcc1b3e9e",
      "de5b63ff66a64cd494dd01fb8b2c300b",
      "9a370e88b8634fe3bb1ea54574850876",
      "3f73194b3667427793018c0b01aee67a",
      "48522ed119734421a4a2b772e11a9193",
      "355db31a689845919a3ae4abfa5f1206",
      "d178be31756e48279ebe2613198b85bc",
      "44f9b1ce373a4e9882b6e53730bae61e",
      "19cef9c5bff340479650db24a264f6ac",
      "207f069305bd4b42a47fb4aa90cdb5d7",
      "c06423c317a24836914caa984e68ed12",
      "5492273f48834fef8f86f4e01a03d3dc",
      "eb828462d9f34cbda765bdb5d437bede",
      "e0b8c24e6b0f419686041bb0073a5ffd",
      "3ebce3ebe75d400a8d0d266cec1b3edc",
      "15dde49b67bd4527bb6974f27ed6db6b",
      "7275f68af92841cd821a897ca40763ee",
      "b83b898cb23440c19f9821760fe8fcd1",
      "ae737422f42f4e418600b86d4fe9b1c5",
      "890d3b1d5f5041198f54f57fb2eba39a",
      "13bc3a35ec104026abc9b62b26d87ea3",
      "9c8ef93675b248abb4dc5775014cd616",
      "3f27aa7a006d4ba5bc137f77a44a4442",
      "4d053c0f502c467280c52c989dfb436a",
      "aefdc6f90b304901bb0c8015191bbe10",
      "6e1304277b6f47c886147f6e26926243",
      "e5d9d2d568a34dad82228c1b12b6ecc8",
      "e5e93f5e1e3c4d72a75efb140e9ba09a",
      "eb10725b535847f6bac7cd98e52e5fe0",
      "8565f0fd6b61498792fc71f2e649dd2f",
      "451afdc4c36a4ea6846524000f987426",
      "b3331aaf66b546f09d5ac3a4f9ceac69",
      "9f939e6a633a4c938a78d5ca49ac9096",
      "7c1ace1990254d9e867a5bcffc3f50d8",
      "6c23afe755714bbe9a3681abc8a013db",
      "01205c8432db4ccaac862f954d1db541",
      "62bb04cbaf8d4025818d8f51d368dd57",
      "eab5b7b41654495588231e3e7f6541ef",
      "5d62dcc15e98449b828fe3983a5d1fca",
      "d8ebe4842633475bb72de2d9179916ba",
      "602435540eec4fe5850631c5cda78c3c",
      "5fd12a1201eb4c0a880d0cf7d02de4ee",
      "3566a5a7dcf14999a72af42a8cafa00f",
      "1cc5521bfd8e42bebcad8ddf284be0b3",
      "c548a4307f0148b1afb72e974a9cd962",
      "efa060ab96624c0ab20fcca750726978",
      "51377b662bb54856ac1c33a6adbf41d3",
      "4992b83b272d4ceb8bf00f6e43316944",
      "f23f03d26e9443a8b80b680062ac3308",
      "74d0636d375b46d580ed802abaf63def",
      "e483456df41e4e65b798839642abde90",
      "0f101d2d6240497bb1cd31a5fae74671",
      "ac1db239e5c440918758a188a337a3f2",
      "c8ac722449fe481194b454513219a7f6",
      "150a1c15777946aba4e84c7296d83f41",
      "1ab0615225684424bcf8af71a5299ed6",
      "b81e599efa3340f98ea8aed74eec35a6",
      "96e6f961023748868b92f8966e0e7fa4",
      "57367adc9474458a8f46be4cc9610f11",
      "0cc0a11bf12b4bda867d852c3cc9ef33",
      "832259169fc54a72a0fa747e30c881b0",
      "652a7dd23dd64543a64f7f092c6513c1",
      "8921c154565549279ff28c536d7f4bd4",
      "3b7537ec09024eeda20cc1b8efe7ea82",
      "b2cdfc86c60e41f9b91a5bcc2e5163b2",
      "8aa7e558d3584e3bbef769e56cade2e1",
      "c5d038b1a7324bdf8d06a63585f86321",
      "c5f1c3d3d35a4ee68a5fc701e8a9a333",
      "c32753b80765480daa0305c0d6be5392",
      "a41c7554e5b64e889ccaab9aeb5d941c",
      "b9ce4aa52d2b490092c014a1fdf2bec8",
      "1d26d11dc5834b938e7ce1f171f1282f",
      "c9246851ffbb41359913c4c8021bbf92",
      "adb8e58431504bbca5eaf889fd7569c5",
      "800ec0f5fce447b3af439e46e06aad70",
      "e9a5ebd9860e42108d9bf4c2880f32a5",
      "f6bc929480a14a06b8c4928e5dfc3ee5",
      "384f9223e71c4d43af000a7e58d2d575",
      "4b3d22c2d0da42fcb9daa1357f309d3d",
      "18625f4819c54afc8c6d55658cd43611",
      "92d7e7d129694ef9abcc15eee4e1f3c4",
      "097443669f044f858ba63bd8ae36faae",
      "bc11042cb0144a9aa03057f0d9446e87",
      "18b9e0cf85f44a09b5865e0ef287172e",
      "9377897cc99a41b5a6f7cbebb04cb868",
      "ffe282bac7734358898dfda44d091f00",
      "859f09b026a84c478df572164d2bd7cb",
      "3080a0db53084ab88820101612b06fad",
      "ec3fa1b570154d50a96523128e7fc318",
      "a38f390cd64b4c8ba5bb3356c72d40c2",
      "73fd5c43b21144e5b8b70047e9f17c80",
      "88d2283484a34af6a63cfda9e50c7e46",
      "eba429e8f92f43a4a065e2f9c96e716a",
      "8752101eca1243cea4b9f4e598075496",
      "288d238dd4454d05b51774231ec4077f",
      "fdc942b3822946cc802c0c0bbe0394a7",
      "4183ae7c20be40a0842241854a8e07dc",
      "6d4da04d4db8412ab018e9d544277e3e",
      "cdb80c14b0474838af6d1dc2854ac4a0",
      "1d1d4008a9c8499c8ac131fbd06a6895",
      "de97b759e66341088eeba6d3d7b7dc35",
      "0981c76a0f8a4b9c9f84075f41f1b7ab",
      "e359edfa9529437c8e8a00c015e15765",
      "ec1defb2075e40e88e6b5a1fce6a0f99",
      "c50aae345c5940b7afa709fb3001e9df",
      "49b9d3817e1f43389f66b15418b1b4f4",
      "e5c203f7e60e41a59f198291ae5ac580",
      "3b86edf677674aabbc00d6dae1459fa7",
      "7c85df02b747474c99701e100d14eae8",
      "f5570b5ade634f189573f86387c85ef1",
      "d8fd28517ea449858dc956c91cce4bb2",
      "d93712ec3df3436aa4a1f6a6b7cd4f32",
      "85440dd723f841998e1ea6df3e143608",
      "cb44e09ac95c4b2dbc74def712f03461",
      "bdf9c859c9e142a89ce78562d81340ed",
      "e3b2dd87a57c430c8dadb3d0afe8b4f5",
      "bb26c6b5af5a40af817af8016c82970f",
      "c26ceb28567c4f3f84e752dbdd91a20a",
      "3d5c66bebab5407ab64338b3d085acb6",
      "d1b1b9ab97704b96ae403914772a23de",
      "4a3e0f6550474c99bf79ad0021923f0b",
      "a32d97f13da1426ba276fd81fb86135e",
      "2ef321cb38294af2b92ef6c535655995",
      "051edbec59374e7e93cdd02169c99cfd",
      "4c68bf4071154b12baf00613af43eccd",
      "296ec0621c37406fbf69a43620b613ad",
      "f9f737387da34910a79d50ccd6beb4d3",
      "5a181c76111a4d93a1a05f4df3f7a6a4",
      "7ff99facef0243f6bcb16778f3038c52",
      "bff02adc159f448a86371f9d5af0a0af"
     ]
    },
    "id": "TfhfzqkoSJ1I",
    "outputId": "5126f9e0-874c-4a3d-8081-e58506865c9d"
   },
   "outputs": [],
   "source": [
    "representation_model = MaximalMarginalRelevance(diversity=0.0)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "## Uncomment the below to not remove stop words\n",
    "## vectorizer_model = None\n",
    "## topic_model = BERTopic(calculate_probabilities=True, representation_model=representation_model, vectorizer_model=vectorizer_model, language = 'multilingual')\n",
    "topic_model = BERTopic(\n",
    "    calculate_probabilities=True, ctfidf_model=ctfidf_model, language=\"multilingual\"\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(texts, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A5O3KpHTnVpz"
   },
   "source": [
    "## Extracting Topics\n",
    "\n",
    "After fitting our model, we can start by looking at the results. Usually, the `-1` topic refers to all outliers and can be ignored. It is also usually the biggest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ScBUgXn06IK6",
    "outputId": "e5f9b35f-a7d4-4629-e72d-7560240e7fcc"
   },
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the topics are based on the most probable words. You can easily change them (I will show you this later). However, before, you do that you should carefully understand what the topics are about. There is no way around it but reading at least some of the texts and looking at graphs below. The most probable words might be also of help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVpvT4bA6KiN",
    "outputId": "9cf99b89-30bb-45fe-b98b-063f8f3624d9"
   },
   "outputs": [],
   "source": [
    "## Print out the most probable words for a topic\n",
    "topic_n = 0\n",
    "topic_model.get_topic(topic_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "M8c8LenB8Zyl"
   },
   "source": [
    "## Visualize Topics\n",
    "\n",
    "After having trained our `BERTopic` model, we can iteratively go through perhaps a hundred topics to get a good understanding of the topics that were extracted. However, that takes quite some time and lacks a global representation. The graph below shows how similar are topics to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "S9qDqEHddgKq",
    "outputId": "3fddd5f1-194e-4708-a7dc-f0c5602c140a"
   },
   "outputs": [],
   "source": [
    "## You can move the slider below that highlights the topics.\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ITB7bf6q8nWQ"
   },
   "source": [
    "## Visualize Topic Probabilities\n",
    "\n",
    "We can quite easily see how probable are the topics for any given document. Basically, by setting `document_n` we can see what topics saturate the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_n = 0\n",
    "topic_model.visualize_distribution(probs[document_n], min_probability=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can see which words decide that the document is in the given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the topic distributions on a token-level\n",
    "topic_distr, topic_token_distr = topic_model.approximate_distribution(\n",
    "    texts, calculate_tokens=True\n",
    ")\n",
    "\n",
    "# Visualize the token-level distributions\n",
    "topic_model.visualize_approximate_distribution(\n",
    "    texts[document_n], topic_token_distr[document_n]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QHRTeSpl5JYB"
   },
   "source": [
    "## Visualize Topic Hierarchy\n",
    "\n",
    "In general, the graph below shows which topics converge (are similar to one another). However, in most of the cases we have a bigger number of documents, therefore, there are at least tens of different topics. In our case, we can see that some of them are similar but I would not reduce their number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4spXl2_C6flq"
   },
   "source": [
    "## Visualize Terms\n",
    "\n",
    "We can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "zpm9LsKW6mi5",
    "outputId": "1197affc-dde2-44c1-9ba7-c9fb36a1143c"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCPdi6_z6sbT"
   },
   "source": [
    "## Visualize Topic Similarity\n",
    "Having generated topic embeddings, through both c-TF-IDF and embeddings, we can create a similarity matrix by simply applying cosine similarities through those topic embeddings. The result will be a matrix indicating how similar certain topics are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "edzNhZuZ6wTr",
    "outputId": "e01231db-fe82-49d3-a96f-8135522d9b9b"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=1, width=1000, height=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D48ienfZrfP0"
   },
   "source": [
    "# Topic Representation\n",
    "\n",
    "After having created the topic model and looking at graphs it would be good to see some texts that are representative for each of the topics. Based on that we can try to name them (however, in our case I would still recommend reading all the texts). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is just a dictionary where keys are topics numbers\n",
    "## and values list with 3 most representative texts\n",
    "topic_model.representative_docs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_n = 0\n",
    "topic_model.representative_docs_[topic_n]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the reading we can add our custom labels to the topics. It is quite straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.set_topic_labels({-1: \"Trash\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see what topics were assigned to each document. To write it out to an Excel file we use method `topic_model.get_document_info(texts).to_excel('topics.xlsx')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can add topics to the our original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the column with topics\n",
    "df[\"topic\"] = topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just out of curiosity, we can see the upvote ration, score, and sentiment for each topic\n",
    "df.groupby(\"topic\").mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do later is to count the average sentiment for each topic's comments. For now, though, here is the Excel file with topics assigned to each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"submissions.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
